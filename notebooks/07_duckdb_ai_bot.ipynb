{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk537Dj5IcFmySqNLrJMcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/foursquare_ai/blob/master/notebooks/07_duckdb_ai_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the Python Environment"
      ],
      "metadata": {
        "id": "89XdE0RGkQfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs4zr46SQDV9"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet duckdb jupysql duckdb-engine\n",
        "## Langchain Framework\n",
        "!pip install --quiet langchain langchain-community langchain-openai langgraph \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import files\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Check if .env file exists, if not, prompt for upload\n",
        "if not os.path.exists(\".env\"):\n",
        "    uploaded = files.upload()\n",
        "    if \".env\" not in uploaded:\n",
        "        print(\"Please upload a .env file to proceed.\")\n",
        "    else:\n",
        "        with open(\".env\", \"wb\") as f:\n",
        "            f.write(uploaded[\".env\"])\n",
        "        load_dotenv(dotenv_path = \".env\", override=True)\n",
        "else:\n",
        "    load_dotenv(dotenv_path = \".env\", override=True)"
      ],
      "metadata": {
        "id": "rcdMclIzTa5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"sql_agent_project\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\") # Ensure you have a way to get this"
      ],
      "metadata": {
        "id": "IzeHu2FolbhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Engineering Part\n",
        "\n",
        "- Here we will prepare the data for our analysis\n",
        "- Clean Data\n",
        "- Load it to local storage for faster loading and querying"
      ],
      "metadata": {
        "id": "bQUQd6DskT1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DuckDB connection\n",
        "con = duckdb.connect()\n",
        "\n",
        "# Load required extensions\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs; INSTALL spatial; LOAD spatial;\")\n",
        "\n",
        "s3_places_path = 's3://fsq-os-places-us-east-1/release/dt=2025-09-09/places/parquet/places-*.zstd.parquet'\n",
        "s3_categories_path = 's3://fsq-os-places-us-east-1/release/dt=2025-09-09/categories/parquet/categories.zstd.parquet'\n",
        "\n",
        "# Execute the SELECT query and create a view\n",
        "con.execute(f\"\"\"\n",
        "CREATE OR REPLACE VIEW places_with_categories AS\n",
        "WITH places AS (\n",
        "    SELECT\n",
        "        DISTINCT UNNEST(P.fsq_category_ids) as fsq_category_id,\n",
        "        name,\n",
        "        postcode,\n",
        "        address,\n",
        "        region,\n",
        "        ST_Point(longitude, latitude) AS geom\n",
        "    FROM read_parquet('{s3_places_path}') AS P\n",
        "    WHERE latitude IS NOT NULL AND longitude IS NOT NULL AND country='IN'\n",
        "),\n",
        "places_with_categories AS (\n",
        "    SELECT\n",
        "        P.name AS name,\n",
        "        C.level1_category_name AS category_level_1,\n",
        "        C.level2_category_name AS category_level_2,\n",
        "        postcode,\n",
        "        address,\n",
        "        region,\n",
        "        P.geom\n",
        "    FROM places AS P\n",
        "    JOIN read_parquet('{s3_categories_path}') AS C\n",
        "    ON P.fsq_category_id = C.category_id\n",
        ")\n",
        "SELECT\n",
        "    name,\n",
        "    category_level_1,\n",
        "    category_level_2,\n",
        "    address,\n",
        "    region,\n",
        "    postcode,\n",
        "    geom\n",
        "FROM places_with_categories;\n",
        "\"\"\")\n",
        "\n",
        "# Export the view to GeoParquet\n",
        "con.execute(\"COPY (SELECT * FROM places_with_categories) TO 'output.geoparquet' WITH (FORMAT PARQUET, CODEC ZSTD);\")\n",
        "\n",
        "## Check the total count of the database:\n",
        "# con.execute(\"SELECT COUNT(*) FROM places_with_categories;\")\n",
        "# result = con.fetchone()[0]\n",
        "# print(result)\n",
        "## Around 1358392 points are there\n",
        "\n",
        "# Close the connection\n",
        "con.close()"
      ],
      "metadata": {
        "id": "ldsOwjrka_mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI ChatBot\n",
        "\n",
        "-"
      ],
      "metadata": {
        "id": "uFGrjdtDgnhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions\n",
        "\n",
        "- Setting up connection with duckdb\n",
        "- Then generating shema details for all the tables in the database"
      ],
      "metadata": {
        "id": "4HwEcFaqj0-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_sql(sql_query: str, con):\n",
        "    try:\n",
        "        # Replace {s3_path} if not already in the query\n",
        "        result = con.execute(sql_query).fetchall()\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error executing SQL: {str(e)}\"\n",
        "\n",
        "def get_duckdb_connection():\n",
        "    con = duckdb.connect(database=':memory:')  # In-memory for simplicity; use a file path for persistence if needed\n",
        "    con.execute(\"INSTALL httpfs;\")\n",
        "    con.execute(\"LOAD httpfs;\")\n",
        "    # Optional: Set S3 region if needed (public bucket, so usually not required)\n",
        "    # con.execute(\"SET s3_region='us-east-1';\")\n",
        "    return con\n",
        "\n",
        "def get_db_schema(DATA_PATH, columns, duckdb_conn, limit=5):\n",
        "\n",
        "    data_schema = f\"\"\"Columns:\\n\"\"\"\n",
        "\n",
        "    sql_query = f\"SELECT {\",\".join(columns)} FROM read_parquet('{DATA_PATH}') WHERE 1=1\"\n",
        "\n",
        "    for column in columns:\n",
        "        sql_query += f\" AND {column} IS NOT NULL\"\n",
        "\n",
        "    sql_query += f\" LIMIT {limit};\"\n",
        "    sample_result = execute_sql(sql_query, duckdb_conn)\n",
        "\n",
        "    schema_details = execute_sql(f'DESCRIBE {sql_query}', duckdb_conn)\n",
        "\n",
        "    for i, column in enumerate(columns):\n",
        "        data_type = schema_details[i][1]\n",
        "        sample_values = \",\".join([str(r[i]) for r in sample_result])\n",
        "        data_schema += f\"{i+1}. Name: {column} | Data Type: {data_type} | Sample values: {sample_values}\"\n",
        "        data_schema += \"\\n\"\n",
        "    return data_schema"
      ],
      "metadata": {
        "id": "WYQkUDLBhFHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duckdb_conn = get_duckdb_connection()\n",
        "\n",
        "DATA_PATH = \"/content/output.geoparquet\"\n",
        "columns = ['name', 'category_level_1', 'category_level_2', 'address', 'region', 'postcode']\n",
        "\n",
        "table_info = get_db_schema(DATA_PATH, columns, duckdb_conn, limit=10)\n",
        "print(table_info)"
      ],
      "metadata": {
        "id": "BsiVwNy4hXLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the chatbot"
      ],
      "metadata": {
        "id": "a4jyhz_Ijwiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LLM (replace with your API key)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)  # Or ChatGroq(model=\"grok-beta\", api_key=\"YOUR_XAI_API_KEY\")\n",
        "\n",
        "# Pre-prompt for NL-to-SQL (customize this!)\n",
        "# Updated prompt to include required input variables for create_sql_query_chain\n",
        "# and incorporate the S3_PATH as a partial variable\n",
        "SQL_PROMPT_TEMPLATE = \"\"\"\n",
        "You are a SQL expert for querying Foursquare POI data using DuckDB. The data is in Parquet files at {s3_path}.\n",
        "The schema includes columns: name (string), country (string, e.g., 'IN' for India), location (struct with lat/lng), categories (array), etc.\n",
        "\n",
        "Based on the schema below and the user's question, generate a valid DuckDB SQL query.\n",
        "Schema:\n",
        "{table_info}\n",
        "\n",
        "Contraints:\n",
        "Always restrict the oulets aka POI withing INDIA so always use country = 'IN' in WHERE clause in all generated SQL queries.\n",
        "If any country is asked by the uers just say something like beyond scope and donot generate any sql prompt\"\n",
        "\n",
        "User question: {input}\n",
        "Limit the results to {top_k}.\n",
        "\n",
        "Generate a valid DuckDB SQL query to answer this. Always use read_parquet('{s3_path}') as the data source.\n",
        "Do not add explanations; output only the SQL query.\n",
        "Examples:\n",
        "- Question: How many Starbucks Outlets are there in India?\n",
        "  SQL: SELECT COUNT(*) as count FROM read_parquet('{s3_path}') WHERE LOWER(name) LIKE '%starbucks%' OR '%starbucks%' IN (SELECT LOWER(unnest(fsq_category_labels))))\n",
        "AND country = 'IN';\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template with the required input variables and partial variable for S3_PATH\n",
        "sql_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"top_k\", \"table_info\"],\n",
        "    template=SQL_PROMPT_TEMPLATE,\n",
        "    partial_variables={\"s3_path\": DATA_PATH}\n",
        ")\n",
        "\n",
        "# # Now create the chain using the updated prompt\n",
        "# sql_chain = create_sql_query_chain(llm=llm, db=db, prompt=sql_prompt)\n",
        "\n",
        "chain = sql_prompt\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"input\": \"Show me the number of outlets in Gurgaon area?\",\n",
        "        \"top_k\": 10,\n",
        "        \"table_info\": table_info\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "erVSH0uIjv7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "uCmJ_e_joVyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}