{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/foursquare_ai/blob/master/notebooks/05_sql_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npb4gTelcmKU"
      },
      "source": [
        "# Build a Question/Answering system over SQL data\n",
        "\n",
        "[REFERENCE](https://python.langchain.com/docs/tutorials/sql_qa/)\n",
        "\n",
        ":::info Prerequisites\n",
        "\n",
        "This guide assumes familiarity with the following concepts:\n",
        "\n",
        "- [Chat models](/docs/concepts/chat_models)\n",
        "- [Tools](/docs/concepts/tools)\n",
        "- [Agents](/docs/concepts/agents)\n",
        "- [LangGraph](/docs/concepts/architecture/#langgraph)\n",
        "\n",
        ":::\n",
        "\n",
        "Enabling a LLM system to query structured data can be qualitatively different from unstructured text data. Whereas in the latter it is common to generate text that can be searched against a vector database, the approach for structured data is often for the LLM to write and execute queries in a DSL, such as SQL. In this guide we'll go over the basic ways to create a Q&A system over tabular data in databases. We will cover implementations using both [chains](/docs/tutorials/sql_qa#chains) and [agents](/docs/tutorials/sql_qa#agents). These systems will allow us to ask a question about the data in a database and get back a natural language answer. The main difference between the two is that our agent can query the database in a loop as many times as it needs to answer the question.\n",
        "\n",
        "## ⚠️ Security note ⚠️\n",
        "\n",
        "Building Q&A systems of SQL databases requires executing model-generated SQL queries. There are inherent risks in doing this. Make sure that your database connection permissions are always scoped as narrowly as possible for your chain/agent's needs. This will mitigate though not eliminate the risks of building a model-driven system. For more on general security best practices, [see here](/docs/security).\n",
        "\n",
        "\n",
        "## Architecture\n",
        "\n",
        "At a high-level, the steps of these systems are:\n",
        "\n",
        "1. **Convert question to SQL query**: Model converts user input to a SQL query.\n",
        "2. **Execute SQL query**: Execute the query.\n",
        "3. **Answer the question**: Model responds to user input using the query results.\n",
        "\n",
        "Note that querying data in CSVs can follow a similar approach. See our [how-to guide](/docs/how_to/sql_csv) on question-answering over CSV data for more detail.\n",
        "\n",
        "![sql_usecase.png](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/sql_usecase.png?raw=1)\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, get required packages and set environment variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xjdfSEqWcmKZ"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet langchain-community langgraph langchain_openai\n",
        "\n",
        "## Download the sql file that will be used to create the Database\n",
        "!wget  https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql -O Chinook_Sqlite.sql"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Database"
      ],
      "metadata": {
        "id": "2ksYpeZcfUDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Name your database file\n",
        "db_path = \"Chinook.db\"\n",
        "\n",
        "# Connect (will create file if it doesn't exist)\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# Read your .sql file\n",
        "with open(\"Chinook_Sqlite.sql\", \"r\") as f:  # replace with your uploaded file name\n",
        "    sql_script = f.read()\n",
        "\n",
        "# Execute the entire SQL script at once\n",
        "conn.executescript(sql_script)\n",
        "\n",
        "# Commit & close\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"Database created at\", db_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkqWzwe2eNo3",
        "outputId": "b2a40897-1f54-4514-a593-243d9af6edea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database created at Chinook.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADModb7RcmKb"
      },
      "source": [
        "### Sample data\n",
        "\n",
        "The below example will use a SQLite connection with the Chinook database, which is a sample database that represents a **digital media store**.\n",
        "\n",
        "The database is structured to mimic real-world business scenarios, with tables representing the artists, albums, tracks, customers, and employees of a music shop.\n",
        "\n",
        "Follow [these installation steps](https://database.guide/2-sample-databases-sqlite/) to create `Chinook.db` in the same directory as this notebook. You can also download and build the database via the command line:\n",
        "```bash\n",
        "curl -s https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql | sqlite3 Chinook.db\n",
        "```\n",
        "\n",
        "Now, `Chinook.db` is in our directory and we can interface with it using the SQLAlchemy-driven `SQLDatabase` class:\n",
        "\n",
        "[DB Diagram](https://dbdocs.io/nafawon167/ChinookDB?view=relationships)\n",
        "\n",
        "\n",
        "Here is the diagram:\n",
        "\n",
        "![Image](https://github.com/kavyajeetbora/foursquare_ai/blob/master/Chinook_DB.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the Database"
      ],
      "metadata": {
        "id": "XtPuY5cSfYlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconnect to check tables\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(\"Tables:\", cursor.fetchall())\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRsW3FbfeeUW",
        "outputId": "8082b634-8458-4caa-caaf-65b4d876894f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables: [('Album',), ('Artist',), ('Customer',), ('Employee',), ('Genre',), ('Invoice',), ('InvoiceLine',), ('MediaType',), ('Playlist',), ('PlaylistTrack',), ('Track',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "vka7ovDtcmKc",
        "outputId": "6ad12e33-c7e1-42f6-84b9-b51783e4acae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sqlite\n",
            "Usable tables in the database: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[(1, 'Adams', 'Andrew', 'General Manager', None, '1962-02-18 00:00:00', '2002-08-14 00:00:00', '11120 Jasper Ave NW', 'Edmonton', 'AB', 'Canada', 'T5K 2N1', '+1 (780) 428-9482', '+1 (780) 428-3457', 'andrew@chinookcorp.com'), (2, 'Edwards', 'Nancy', 'Sales Manager', 1, '1958-12-08 00:00:00', '2002-05-01 00:00:00', '825 8 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 2T3', '+1 (403) 262-3443', '+1 (403) 262-3322', 'nancy@chinookcorp.com'), (3, 'Peacock', 'Jane', 'Sales Support Agent', 2, '1973-08-29 00:00:00', '2002-04-01 00:00:00', '1111 6 Ave SW', 'Calgary', 'AB', 'Canada', 'T2P 5M5', '+1 (403) 262-3443', '+1 (403) 262-6712', 'jane@chinookcorp.com'), (4, 'Park', 'Margaret', 'Sales Support Agent', 2, '1947-09-19 00:00:00', '2003-05-03 00:00:00', '683 10 Street SW', 'Calgary', 'AB', 'Canada', 'T2P 5G3', '+1 (403) 263-4423', '+1 (403) 263-4289', 'margaret@chinookcorp.com'), (5, 'Johnson', 'Steve', 'Sales Support Agent', 2, '1965-03-03 00:00:00', '2003-10-17 00:00:00', '7727B 41 Ave', 'Calgary', 'AB', 'Canada', 'T3B 1Y7', '1 (780) 836-9987', '1 (780) 836-9543', 'steve@chinookcorp.com'), (6, 'Mitchell', 'Michael', 'IT Manager', 1, '1973-07-01 00:00:00', '2003-10-17 00:00:00', '5827 Bowness Road NW', 'Calgary', 'AB', 'Canada', 'T3B 0C5', '+1 (403) 246-9887', '+1 (403) 246-9899', 'michael@chinookcorp.com'), (7, 'King', 'Robert', 'IT Staff', 6, '1970-05-29 00:00:00', '2004-01-02 00:00:00', '590 Columbia Boulevard West', 'Lethbridge', 'AB', 'Canada', 'T1K 5N8', '+1 (403) 456-9986', '+1 (403) 456-8485', 'robert@chinookcorp.com'), (8, 'Callahan', 'Laura', 'IT Staff', 6, '1968-01-09 00:00:00', '2004-03-04 00:00:00', '923 7 ST NW', 'Lethbridge', 'AB', 'Canada', 'T1H 1Y8', '+1 (403) 467-3351', '+1 (403) 467-8772', 'laura@chinookcorp.com')]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
        "print(db.dialect)\n",
        "print(\"Usable tables in the database:\", db.get_usable_table_names())\n",
        "db.run(\"SELECT * FROM Employee LIMIT 10;\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySGoSJ-dcmKd"
      },
      "source": [
        "Great! We've got a SQL database that we can query. Now let's try hooking it up to an LLM.\n",
        "\n",
        "## Chains {#chains}\n",
        "\n",
        "Chains are compositions of predictable steps. In [LangGraph](/docs/concepts/architecture/#langgraph), we can represent a chain via simple sequence of nodes. Let's create a sequence of steps that, given a question, does the following:\n",
        "- converts the question into a SQL query;\n",
        "- executes the query;\n",
        "- uses the result to answer the original question.\n",
        "\n",
        "There are scenarios not supported by this arrangement. For example, this system will execute a SQL query for any user input-- even \"hello\". Importantly, as we'll see below, some questions require more than one query to answer. We will address these scenarios in the Agents section.\n",
        "\n",
        "### Application state\n",
        "\n",
        "The LangGraph [state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a `TypedDict`, but can also be a [Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/).\n",
        "\n",
        "For this application, we can just keep track of the input question, generated query, query result, and generated answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZmN8IeScmKe"
      },
      "source": [
        "Now we just need functions that operate on this state and populate its contents.\n",
        "\n",
        "### Convert question to SQL query\n",
        "\n",
        "The first step is to take the user input and convert it to a SQL query. To reliably obtain SQL queries (absent markdown formatting and explanations or clarifications), we will make use of LangChain's [structured output](/docs/concepts/structured_outputs/) abstraction.\n",
        "\n",
        "Let's select a chat model for our application:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O2QVhfmcmKe"
      },
      "source": [
        "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
        "\n",
        "<ChatModelTabs customVarName=\"llm\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv(dotenv_path = '.env', override=True)\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ],
      "metadata": {
        "id": "77XzE-lPg8wp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "A4lMjqV4cmKf"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5QiS6RrcmKf"
      },
      "source": [
        "**Note**:\n",
        "\n",
        "The **system message** in your ChatPromptTemplate is *included every time* you invoke the template for a user query (via .format() or in a chain), so it's passed with each request to the model—not just once at the start. This ensures consistency but watch token costs!\n",
        "\n",
        "Let's provide some instructions for our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "c9hCEIv7cmKg",
        "outputId": "4d6dcf5f-ecb5-4042-e342-6ce9f77e0f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "\n",
            "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
            "run to help find the answer. Unless the user specifies in his question a\n",
            "specific number of examples they wish to obtain, always limit your query to\n",
            "at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to\n",
            "return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a the\n",
            "few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema\n",
            "description. Be careful to not query for columns that do not exist. Also,\n",
            "pay attention to which column is in which table.\n",
            "\n",
            "Only use the following tables:\n",
            "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_message = \"\"\"\n",
        "Given an input question, create a syntactically correct {dialect} query to\n",
        "run to help find the answer. Unless the user specifies in his question a\n",
        "specific number of examples they wish to obtain, always limit your query to\n",
        "at most {top_k} results. You can order the results by a relevant column to\n",
        "return the most interesting examples in the database.\n",
        "\n",
        "Never query for all the columns from a specific table, only ask for a the\n",
        "few relevant columns given the question.\n",
        "\n",
        "Pay attention to use only the column names that you can see in the schema\n",
        "description. Be careful to not query for columns that do not exist. Also,\n",
        "pay attention to which column is in which table.\n",
        "\n",
        "Only use the following tables:\n",
        "{table_info}\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"Question: {input}\"\n",
        "\n",
        "query_prompt_template = ChatPromptTemplate(\n",
        "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
        ")\n",
        "\n",
        "for message in query_prompt_template.messages:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cgb5SA7cmKg"
      },
      "source": [
        "The prompt includes several parameters we will need to populate, such as the SQL dialect and table schemas. LangChain's [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) object includes methods to help with this.\n",
        "\n",
        "### Step-by-step summary:\n",
        "\n",
        "1. **Prompt Template**: You defined a `ChatPromptTemplate` with a system message (instructing the LLM to generate syntactically correct SQL queries for a given dialect, limited to `top_k` results, using specific table info) and a user prompt for the input question.\n",
        "\n",
        "2. **Structured Output with TypedDict**: You used `QueryOutput` (a `TypedDict` with `query: Annotated[str, ..., \"Syntactically valid SQL query.\"]`) to enforce structured LLM output as a dictionary (`{\"query\": str}`), ensuring predictable SQL generation.\n",
        "\n",
        "3. **Pydantic Alternative**: We explored rewriting `QueryOutput` as a Pydantic `BaseModel` (`query: str = Field(..., description=\"...\")`) for runtime validation. The `...` makes `query` required, preventing `None` or missing values, which is ideal for your chatbot.\n",
        "\n",
        "4. **Write Query Function**: The `write_query` function:\n",
        "   - Takes a `state` with the user’s question.\n",
        "   - Populates the prompt template with dialect, `top_k`, table info, and question.\n",
        "   - Uses `llm.with_structured_output(QueryOutput)` to force the LLM to output a `QueryOutput`-compliant dictionary.\n",
        "   - Returns `{\"query\": result[\"query\"]}` for database execution.\n",
        "\n",
        "5. **Key Insight**: `with_structured_output` ensures the LLM doesn’t spit out random text, making your pipeline reliable. Pydantic’s required field (`...`) is recommended over optional fields for robust SQL query generation.\n",
        "\n",
        "6. **Tech Stack**: You’re using LangChain (for chaining), LangGraph (for state), and LangSmith (for tracing)—a scalable combo. Pydantic is preferred over `typing_extensions` for validation and serialization.\n",
        "\n",
        "**Next Steps**: Try implementing the Pydantic `QueryOutput` in your LangChain pipeline and test with a mock DB. Use LangSmith to debug any quirky LLM outputs. Want to code a quick example together? Let me know!\n",
        "\n",
        "\n",
        "Our `write_query` step will just populate these parameters and prompt a model to generate the SQL query:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Define the Models\n",
        "\n",
        "- this will handle the input and output format in structured way"
      ],
      "metadata": {
        "id": "nbdvN9J92ig3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class State(BaseModel):\n",
        "    question: str = \"\"\n",
        "    query: str = \"\"  # Add defaults to make fields optional\n",
        "    result: str = \"\"\n",
        "    answer: str = \"\"\n",
        "\n",
        "class QueryOutput(BaseModel):\n",
        "    query: str = Field(..., description = \"Syntactically valid SQL query.\")"
      ],
      "metadata": {
        "id": "5ljutl15rqJ3"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define each node/function\n",
        "\n",
        "- generate query\n",
        "- execute the query\n",
        "- generate the answer based on user input, query and the result"
      ],
      "metadata": {
        "id": "1REVYzSn2qLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "aeNVAg2ncmKg"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
        "\n",
        "# Write query (fixed earlier)\n",
        "def write_query(state: State):\n",
        "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
        "    prompt = query_prompt_template.invoke(\n",
        "        {\n",
        "            \"dialect\": db.dialect,  # Ensure db is defined\n",
        "            \"top_k\": 10,\n",
        "            \"table_info\": db.get_table_info(),\n",
        "            \"input\": state.question,\n",
        "        }\n",
        "    )\n",
        "    structured_llm = llm.with_structured_output(QueryOutput)  # Ensure llm is defined\n",
        "    result = structured_llm.invoke(prompt)\n",
        "    return {\"query\": result.query}\n",
        "\n",
        "# Execute query (fixed for attribute access)\n",
        "def execute_query(state: State):\n",
        "    \"\"\"Execute SQL query.\"\"\"\n",
        "    execute_query_tool = QuerySQLDatabaseTool(db=db)  # Ensure db is defined\n",
        "    return {\"result\": execute_query_tool.invoke(state.query)}  # Use state.query\n",
        "\n",
        "# Generate answer (already correct)\n",
        "def generate_answer(state: State):\n",
        "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
        "    prompt = (\n",
        "        \"Given the following user question, corresponding SQL query, \"\n",
        "        \"and SQL result, answer the user question.\\n\\n\"\n",
        "        f\"Question: {state.question}\\n\"\n",
        "        f\"SQL Query: {state.query}\\n\"\n",
        "        f\"SQL Result: {state.result}\"\n",
        "    )\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"answer\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WmW_MzcmKh"
      },
      "source": [
        "Let's test it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "T1E917JHcmKh",
        "outputId": "a72eaff3-0ea2-4bd5-c758-6cfea00f4131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated query: SELECT Country, COUNT(*) as CustomerCount \n",
            "FROM Customer \n",
            "GROUP BY Country \n",
            "ORDER BY CustomerCount DESC \n",
            "LIMIT 10;\n",
            "Result: [('USA', 13), ('Canada', 8), ('France', 5), ('Brazil', 5), ('Germany', 4), ('United Kingdom', 3), ('Portugal', 2), ('India', 2), ('Czech Republic', 2), ('Sweden', 1)]\n",
            "\n",
            "AI Response:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The top countries from where our customers come from are:\n",
            "\n",
            "1. USA - 13 customers\n",
            "2. Canada - 8 customers\n",
            "3. France - 5 customers\n",
            "4. Brazil - 5 customers\n",
            "5. Germany - 4 customers\n",
            "6. United Kingdom - 3 customers\n",
            "7. Portugal - 2 customers\n",
            "8. India - 2 customers\n",
            "9. Czech Republic - 2 customers\n",
            "10. Sweden - 1 customer\n"
          ]
        }
      ],
      "source": [
        "# Manual run\n",
        "user_query = \"Give me the top countries from where our customers come from?\"\n",
        "state = State(question=user_query)\n",
        "generated_query = write_query(state)  # Returns {\"query\": \"SELECT COUNT(*) FROM Employee;\"}\n",
        "print(f\"Generated query: {generated_query['query']}\")\n",
        "\n",
        "# Pass State to execute_query\n",
        "state = State(question=user_query, query=generated_query['query'])\n",
        "result = execute_query(state)\n",
        "print(f\"Result: {result['result']}\")\n",
        "\n",
        "# Generate answer\n",
        "state = State(question=user_query, query=generated_query['query'], result=result['result'])\n",
        "ai_response = generate_answer(state)\n",
        "print(\"\\nAI Response:\\n\")\n",
        "print(\"-\"*100)\n",
        "print(ai_response['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9dbHLCncmKj"
      },
      "source": [
        "### Orchestrating with LangGraph\n",
        "\n",
        "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the three steps into a single sequence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, StateGraph, END\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "# Graph setup\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_sequence([write_query, execute_query, generate_answer])\n",
        "graph_builder.add_edge(START, \"write_query\")\n",
        "graph_builder.add_edge(\"generate_answer\", END)\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "tL6zxQAfD1OQ"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "69bFrtWkcmKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab60768-84db-4111-91a0-2140905c6cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'write_query': {'query': 'SELECT COUNT(*) AS TotalSongs FROM Track;'}}\n",
            "{'execute_query': {'result': '[(3503,)]'}}\n",
            "{'generate_answer': {'answer': 'There are 3,503 songs in the database.'}}\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "There are 3,503 songs in the database.\n"
          ]
        }
      ],
      "source": [
        "# Invoke graph with stream\n",
        "# question = \"List the top buyers with their personal info, contry they belong to along with total number of orders?\"\n",
        "question = \"How many songs are there in the database? \"\n",
        "for step in graph.stream(\n",
        "    {\n",
        "        \"question\": question,\n",
        "        \"query\": \"\",\n",
        "        \"result\": \"\",\n",
        "        \"answer\": \"\"\n",
        "    },\n",
        "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)\n",
        "\n",
        "print(\"-\"*100,\"\\n\")\n",
        "print(step['generate_answer']['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke graph to get final result\n",
        "# question = \"List the top buyers with their personal info, contry they belong to along with total number of orders?\"\n",
        "question = \"Give me the top songs that were most played along with the artist name and number of times it was played\"\n",
        "final_state = graph.invoke(\n",
        "    {\n",
        "        \"question\": question,\n",
        "        \"query\": \"\",\n",
        "        \"result\": \"\",\n",
        "        \"answer\": \"\"\n",
        "    },\n",
        "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
        ")\n",
        "print(final_state['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKviIfzE9EKl",
        "outputId": "3f4c7bec-a533-44ca-ef07-ac98f3a7b5ae"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top songs that were most played, along with the artist names and the number of times they were played, are as follows:\n",
            "\n",
            "1. **Balls to the Wall** by **Accept** - Played 2 times\n",
            "2. **Inject The Venom** by **AC/DC** - Played 2 times\n",
            "3. **Snowballed** by **AC/DC** - Played 2 times\n",
            "4. **Overdose** by **AC/DC** - Played 2 times\n",
            "5. **Deuces Are Wild** by **Aerosmith** - Played 2 times\n",
            "6. **Not The Doctor** by **Alanis Morissette** - Played 2 times\n",
            "7. **Por Causa De Você** by **Antônio Carlos Jobim** - Played 2 times\n",
            "8. **Welcome Home (Sanitarium)** by **Apocalyptica** - Played 2 times\n",
            "9. **Snowblind** by **Black Sabbath** - Played 2 times\n",
            "10. **Cornucopia** by **Black Sabbath** - Played 2 times\n",
            "\n",
            "All of these songs were played 2 times each.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wlljJwecmKk"
      },
      "source": [
        "Check out the [LangSmith trace](https://smith.langchain.com/public/30a79380-6ba6-46af-8bd9-5d1df0b9ccca/r)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4TVYnIcmKk"
      },
      "source": [
        "### Human-in-the-loop\n",
        "\n",
        "LangGraph supports a number of features that can be useful for this workflow. One of them is [human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): we can interrupt our application before sensitive steps (such as the execution of a SQL query) for human review. This is enabled by LangGraph's [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) layer, which saves run progress to your storage of choice. Below, we specify storage in-memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "bH4TEP6pcmKk"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
        "\n",
        "# Now that we're using persistence, we need to specify a thread ID\n",
        "# so that we can continue the run after review.\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "3o369xhkcmKl",
        "outputId": "72314bff-1bb7-40f0-8b29-aff8819a1c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emIx4JnecmKl"
      },
      "source": [
        "Let's repeat the same run, adding in a simple yes/no approval step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "sc9YSv7LcmKl",
        "outputId": "278dc20b-fd87-4113-a1ef-379d0fcc67b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'write_query': {'query': 'SELECT COUNT(*) AS EmployeeCount FROM Employee;'}}\n",
            "{'__interrupt__': ()}\n",
            "Do you want to go to execute query? (yes/no): yes\n",
            "{'execute_query': {'result': '[(8,)]'}}\n",
            "{'generate_answer': {'answer': 'There are 8 employees.'}}\n"
          ]
        }
      ],
      "source": [
        "for step in graph.stream(\n",
        "    {\"question\": \"How many employees are there?\"},\n",
        "    config,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    print(step)\n",
        "\n",
        "try:\n",
        "    user_approval = input(\"Do you want to go to execute query? (yes/no): \")\n",
        "except Exception:\n",
        "    user_approval = \"no\"\n",
        "\n",
        "if user_approval.lower() == \"yes\":\n",
        "    # If approved, continue the graph execution\n",
        "    for step in graph.stream(None, config, stream_mode=\"updates\"):\n",
        "        print(step)\n",
        "else:\n",
        "    print(\"Operation cancelled by user.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1Kxv_TcmKl"
      },
      "source": [
        "See [this](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/) LangGraph guide for more detail and examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e-z8LPccmKl"
      },
      "source": [
        "### Next steps\n",
        "\n",
        "For more complex query-generation, we may want to create few-shot prompts or add query-checking steps. For advanced techniques like this and more check out:\n",
        "\n",
        "* [Prompting strategies](/docs/how_to/sql_prompting): Advanced prompt engineering techniques.\n",
        "* [Query checking](/docs/how_to/sql_query_checking): Add query validation and error handling.\n",
        "* [Large databases](/docs/how_to/sql_large_db): Techniques for working with large databases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaZT9DNWcmKm"
      },
      "source": [
        "## Agents {#agents}\n",
        "\n",
        "[Agents](/docs/concepts/agents) leverage the reasoning capabilities of LLMs to make decisions during execution. Using agents allows you to offload additional discretion over the query generation and execution process. Although their behavior is less predictable than the above \"chain\", they feature some advantages:\n",
        "\n",
        "- They can query the database as many times as needed to answer the user question.\n",
        "- They can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
        "- They can answer questions based on the databases' schema as well as on the databases' content (like describing a specific table).\n",
        "\n",
        "\n",
        "Below we assemble a minimal SQL agent. We will equip it with a set of tools using LangChain's [SQLDatabaseToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html). Using LangGraph's [pre-built ReAct agent constructor](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent), we can do this in one line.\n",
        "\n",
        ":::tip\n",
        "\n",
        "Check out LangGraph's [SQL Agent Tutorial](https://langchain-ai.github.io/langgraph/tutorials/sql-agent/) for a more advanced formulation of a SQL agent.\n",
        "\n",
        ":::\n",
        "\n",
        "The `SQLDatabaseToolkit` includes tools that can:\n",
        "\n",
        "* Create and execute queries\n",
        "* Check query syntax\n",
        "* Retrieve table descriptions\n",
        "* ... and more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EZBPtV7cmKm",
        "outputId": "8d288e6b-26e6-4588-8170-58f2a01a70fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7b28db10d610>),\n",
              " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7b28db10d610>),\n",
              " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7b28db10d610>),\n",
              " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7b28db10d610>, llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7b27f516f110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b27f5071010>, root_client=<openai.OpenAI object at 0x7b27f6990680>, root_async_client=<openai.AsyncOpenAI object at 0x7b27f60ff740>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7b27f516f110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b27f5071010>, root_client=<openai.OpenAI object at 0x7b27f6990680>, root_async_client=<openai.AsyncOpenAI object at 0x7b27f60ff740>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
        "\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx5E1dx_cmKm"
      },
      "source": [
        "### System Prompt\n",
        "\n",
        "We will also want to load a system prompt for our agent. This will consist of instructions for how to behave. Note that the prompt below has several parameters, which we assign below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxfO4icLcmKs"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are an agent designed to interact with a SQL database.\n",
        "Given an input question, create a syntactically correct {dialect} query to run,\n",
        "then look at the results of the query and return the answer. Unless the user\n",
        "specifies a specific number of examples they wish to obtain, always limit your\n",
        "query to at most {top_k} results.\n",
        "\n",
        "You can order the results by a relevant column to return the most interesting\n",
        "examples in the database. Never query for all the columns from a specific table,\n",
        "only ask for the relevant columns given the question.\n",
        "\n",
        "You MUST double check your query before executing it. If you get an error while\n",
        "executing a query, rewrite the query and try again.\n",
        "\n",
        "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
        "database.\n",
        "\n",
        "To start you should ALWAYS look at the tables in the database to see what you\n",
        "can query. Do NOT skip this step.\n",
        "\n",
        "Then you should query the schema of the most relevant tables.\n",
        "\"\"\".format(\n",
        "    dialect=\"SQLite\",\n",
        "    top_k=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--QkOAx4cmKt"
      },
      "source": [
        "### Initializing agent\n",
        "\n",
        "We will use a prebuilt [LangGraph](/docs/concepts/architecture/#langgraph) agent to build our agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z6zeA1IcmKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a009d544-dc9a-403a-be56-ad268ebf9f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydantic/json_schema.py:319: RuntimeWarning: coroutine '_render_mermaid_using_pyppeteer' was never awaited\n",
            "  mapping[key] = getattr(self, method_name)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, tools, prompt=system_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcN1L7KVcmKt"
      },
      "source": [
        "Consider how the agent responds to the below question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riiTzIZJcmKt",
        "outputId": "39213b5a-a8d1-4897-87ee-d7cc332b99eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Which country's customers spent the most?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_list_tables (call_1WwY7ZlIqdaQcdw6D3KPQhLZ)\n",
            " Call ID: call_1WwY7ZlIqdaQcdw6D3KPQhLZ\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_list_tables\n",
            "\n",
            "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_Zvy2bgrOJr7VxmB8JcNJCsSF)\n",
            " Call ID: call_Zvy2bgrOJr7VxmB8JcNJCsSF\n",
            "  Args:\n",
            "    table_names: Customer\n",
            "  sql_db_schema (call_hLtQWyeqfKZKGbGtSVXPepI4)\n",
            " Call ID: call_hLtQWyeqfKZKGbGtSVXPepI4\n",
            "  Args:\n",
            "    table_names: Invoice\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"Invoice\" (\n",
            "\t\"InvoiceId\" INTEGER NOT NULL, \n",
            "\t\"CustomerId\" INTEGER NOT NULL, \n",
            "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
            "\t\"BillingAddress\" NVARCHAR(70), \n",
            "\t\"BillingCity\" NVARCHAR(40), \n",
            "\t\"BillingState\" NVARCHAR(40), \n",
            "\t\"BillingCountry\" NVARCHAR(40), \n",
            "\t\"BillingPostalCode\" NVARCHAR(10), \n",
            "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
            "\tPRIMARY KEY (\"InvoiceId\"), \n",
            "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Invoice table:\n",
            "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
            "1\t2\t2021-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
            "2\t4\t2021-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
            "3\t8\t2021-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query_checker (call_9X80i93SjsIlD8D6measL5tm)\n",
            " Call ID: call_9X80i93SjsIlD8D6measL5tm\n",
            "  Args:\n",
            "    query: SELECT c.Country, SUM(i.Total) AS TotalSpent \n",
            "FROM Customer c \n",
            "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
            "GROUP BY c.Country \n",
            "ORDER BY TotalSpent DESC \n",
            "LIMIT 5;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query_checker\n",
            "\n",
            "```sql\n",
            "SELECT c.Country, SUM(i.Total) AS TotalSpent \n",
            "FROM Customer c \n",
            "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
            "GROUP BY c.Country \n",
            "ORDER BY TotalSpent DESC \n",
            "LIMIT 5;\n",
            "```\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (call_VvTWgbB2QbsY8cbAOyZihwRN)\n",
            " Call ID: call_VvTWgbB2QbsY8cbAOyZihwRN\n",
            "  Args:\n",
            "    query: SELECT c.Country, SUM(i.Total) AS TotalSpent \n",
            "FROM Customer c \n",
            "JOIN Invoice i ON c.CustomerId = i.CustomerId \n",
            "GROUP BY c.Country \n",
            "ORDER BY TotalSpent DESC \n",
            "LIMIT 5;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query\n",
            "\n",
            "[('USA', 523.0600000000003), ('Canada', 303.9599999999999), ('France', 195.09999999999994), ('Brazil', 190.09999999999997), ('Germany', 156.48)]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The countries where customers spent the most are as follows:\n",
            "\n",
            "1. **USA**: $523.06\n",
            "2. **Canada**: $303.96\n",
            "3. **France**: $195.10\n",
            "4. **Brazil**: $190.10\n",
            "5. **Germany**: $156.48\n"
          ]
        }
      ],
      "source": [
        "question = \"Which country's customers spent the most?\"\n",
        "\n",
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C3c40DNcmKu"
      },
      "source": [
        "You can also use the [LangSmith trace](https://smith.langchain.com/public/8af422aa-b651-4bfe-8683-e2a7f4ccd82c/r) to visualize these steps and associated metadata.\n",
        "\n",
        "Note that the agent executes multiple queries until it has the information it needs:\n",
        "1. List available tables;\n",
        "2. Retrieves the schema for three tables;\n",
        "3. Queries multiple of the tables via a join operation.\n",
        "\n",
        "The agent is then able to use the result of the final query to generate an answer to the original question.\n",
        "\n",
        "The agent can similarly handle qualitative questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C_jGSWscmK2",
        "outputId": "2dc6f777-658e-47ab-9847-e521ea2e217f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Describe the playlisttrack table\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_list_tables (call_Hyq1WYP6JrSPEzbhSgSvk21H)\n",
            " Call ID: call_Hyq1WYP6JrSPEzbhSgSvk21H\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_list_tables\n",
            "\n",
            "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_jDm2009iG4iw5lXiyJZCE9Qw)\n",
            " Call ID: call_jDm2009iG4iw5lXiyJZCE9Qw\n",
            "  Args:\n",
            "    table_names: PlaylistTrack\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"PlaylistTrack\" (\n",
            "\t\"PlaylistId\" INTEGER NOT NULL, \n",
            "\t\"TrackId\" INTEGER NOT NULL, \n",
            "\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \n",
            "\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \n",
            "\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from PlaylistTrack table:\n",
            "PlaylistId\tTrackId\n",
            "1\t3402\n",
            "1\t3389\n",
            "1\t3390\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The `PlaylistTrack` table has the following structure:\n",
            "\n",
            "- **Columns:**\n",
            "  - `PlaylistId` (INTEGER, NOT NULL): This is a foreign key referencing the `Playlist` table.\n",
            "  - `TrackId` (INTEGER, NOT NULL): This is a foreign key referencing the `Track` table.\n",
            "\n",
            "- **Primary Key:** The combination of `PlaylistId` and `TrackId` serves as the primary key for this table, ensuring that each track can only appear once in a playlist.\n",
            "\n",
            "- **Foreign Keys:**\n",
            "  - `TrackId` references the `Track` table's `TrackId`.\n",
            "  - `PlaylistId` references the `Playlist` table's `PlaylistId`.\n",
            "\n",
            "**Sample Rows:**\n",
            "1. PlaylistId: 1, TrackId: 3402\n",
            "2. PlaylistId: 1, TrackId: 3389\n",
            "3. PlaylistId: 1, TrackId: 3390\n",
            "\n",
            "This table essentially links tracks to playlists, allowing for the organization of music tracks into different playlists.\n"
          ]
        }
      ],
      "source": [
        "question = \"Describe the playlisttrack table\"\n",
        "\n",
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42VgSWDgcmK2"
      },
      "source": [
        "### Dealing with high-cardinality columns\n",
        "\n",
        "In order to filter columns that contain proper nouns such as addresses, song names or artists, we first need to double-check the spelling in order to filter the data correctly.\n",
        "\n",
        "We can achieve this by creating a vector store with all the distinct proper nouns that exist in the database. We can then have the agent query that vector store each time the user includes a proper noun in their question, to find the correct spelling for that word. In this way, the agent can make sure it understands which entity the user is referring to before building the target query.\n",
        "\n",
        "First we need the unique values for each entity we want, for which we define a function that parses the result into a list of elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_4mqF_gcmK3",
        "outputId": "07353d1f-489e-4387-d294-5b7c302945b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['In Through The Out Door',\n",
              " 'Transmission',\n",
              " 'Battlestar Galactica (Classic), Season',\n",
              " 'A Copland Celebration, Vol. I',\n",
              " 'Quiet Songs']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ast\n",
        "import re\n",
        "\n",
        "\n",
        "def query_as_list(db, query):\n",
        "    res = db.run(query)\n",
        "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
        "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n",
        "    return list(set(res))\n",
        "\n",
        "\n",
        "artists = query_as_list(db, \"SELECT Name FROM Artist\")\n",
        "albums = query_as_list(db, \"SELECT Title FROM Album\")\n",
        "albums[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsFlouj8cmK3"
      },
      "source": [
        "Using this function, we can create a **retriever tool** that the agent can execute at its discretion.\n",
        "\n",
        "Let's select an [embeddings model](/docs/integrations/text_embedding/) and [vector store](/docs/integrations/vectorstores/) for this step:\n",
        "\n",
        "**Select an embedding model**:\n",
        "\n",
        "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
        "\n",
        "<EmbeddingTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w7mx870cmK3"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynDnNy0UcmK3"
      },
      "source": [
        "**Select a vector store**:\n",
        "\n",
        "import VectorStoreTabs from \"@theme/VectorStoreTabs\";\n",
        "\n",
        "<VectorStoreTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPXWXVstcmK3"
      },
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbBzhnE3cmK3"
      },
      "source": [
        "We can now construct a retrieval tool that can search over relevant proper nouns in the database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OZFedFlcmK4"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "\n",
        "_ = vector_store.add_texts(artists + albums)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "description = (\n",
        "    \"Use to look up values to filter on. Input is an approximate spelling \"\n",
        "    \"of the proper noun, output is valid proper nouns. Use the noun most \"\n",
        "    \"similar to the search.\"\n",
        ")\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"search_proper_nouns\",\n",
        "    description=description,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJC3w2SScmK4"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWlonxuucmK4",
        "outputId": "6b1c7ea9-3592-49fb-e815-1356ae6b586d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alice In Chains\n",
            "\n",
            "Alanis Morissette\n",
            "\n",
            "Pearl Jam\n",
            "\n",
            "Pearl Jam\n",
            "\n",
            "Audioslave\n"
          ]
        }
      ],
      "source": [
        "print(retriever_tool.invoke(\"Alice Chains\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gu1G6g3cmK4"
      },
      "source": [
        "This way, if the agent determines it needs to write a filter based on an artist along the lines of \"Alice Chains\", it can first use the retriever tool to observe relevant values of a column.\n",
        "\n",
        "Putting this together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2DFVE1BcmK4"
      },
      "outputs": [],
      "source": [
        "# Add to system message\n",
        "suffix = (\n",
        "    \"If you need to filter on a proper noun like a Name, you must ALWAYS first look up \"\n",
        "    \"the filter value using the 'search_proper_nouns' tool! Do not try to \"\n",
        "    \"guess at the proper name - use this function to find similar ones.\"\n",
        ")\n",
        "\n",
        "system = f\"{system_message}\\n\\n{suffix}\"\n",
        "\n",
        "tools.append(retriever_tool)\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt=system)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfDpsiSZcmK5",
        "outputId": "336595f3-963d-401f-f96e-b6cf98189822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "How many albums does alis in chain have?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search_proper_nouns (call_8ryjsRPLAr79mM3Qvnq6gTOH)\n",
            " Call ID: call_8ryjsRPLAr79mM3Qvnq6gTOH\n",
            "  Args:\n",
            "    query: alis in chain\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_proper_nouns\n",
            "\n",
            "Alice In Chains\n",
            "\n",
            "Aisha Duo\n",
            "\n",
            "Xis\n",
            "\n",
            "Da Lama Ao Caos\n",
            "\n",
            "A-Sides\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_list_tables (call_NJjtCpU89MBMplssjn1z0xzq)\n",
            " Call ID: call_NJjtCpU89MBMplssjn1z0xzq\n",
            "  Args:\n",
            "  search_proper_nouns (call_1BfrueC9koSIyi4OfMu2Ao8q)\n",
            " Call ID: call_1BfrueC9koSIyi4OfMu2Ao8q\n",
            "  Args:\n",
            "    query: Alice In Chains\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_proper_nouns\n",
            "\n",
            "Alice In Chains\n",
            "\n",
            "Pearl Jam\n",
            "\n",
            "Pearl Jam\n",
            "\n",
            "Foo Fighters\n",
            "\n",
            "Soundgarden\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_Kn09w9jd9swcNzIZ1b5MlKID)\n",
            " Call ID: call_Kn09w9jd9swcNzIZ1b5MlKID\n",
            "  Args:\n",
            "    table_names: Album, Artist\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"Album\" (\n",
            "\t\"AlbumId\" INTEGER NOT NULL, \n",
            "\t\"Title\" NVARCHAR(160) NOT NULL, \n",
            "\t\"ArtistId\" INTEGER NOT NULL, \n",
            "\tPRIMARY KEY (\"AlbumId\"), \n",
            "\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Album table:\n",
            "AlbumId\tTitle\tArtistId\n",
            "1\tFor Those About To Rock We Salute You\t1\n",
            "2\tBalls to the Wall\t2\n",
            "3\tRestless and Wild\t2\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE \"Artist\" (\n",
            "\t\"ArtistId\" INTEGER NOT NULL, \n",
            "\t\"Name\" NVARCHAR(120), \n",
            "\tPRIMARY KEY (\"ArtistId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Artist table:\n",
            "ArtistId\tName\n",
            "1\tAC/DC\n",
            "2\tAccept\n",
            "3\tAerosmith\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (call_WkHRiPcBoGN9bc58MIupRHKP)\n",
            " Call ID: call_WkHRiPcBoGN9bc58MIupRHKP\n",
            "  Args:\n",
            "    query: SELECT COUNT(*) FROM Album WHERE ArtistId = (SELECT ArtistId FROM Artist WHERE Name = 'Alice In Chains')\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query\n",
            "\n",
            "[(1,)]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Alice In Chains has released 1 album in the database.\n"
          ]
        }
      ],
      "source": [
        "question = \"How many albums does alis in chain have?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV4i4REjcmK5"
      },
      "source": [
        "As we can see, both in the streamed steps and in the [LangSmith trace](https://smith.langchain.com/public/1d757ed2-5688-4458-9400-023594e2c5a7/r), the agent used the `search_proper_nouns` tool in order to check how to correctly query the database for this specific artist."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}