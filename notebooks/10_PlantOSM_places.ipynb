{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/foursquare_ai/blob/master/notebooks/10_PlantOSM_places.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TgP8269lp9Z"
      },
      "source": [
        "# Exploring Foursquare POI Data\n",
        "\n",
        "\n",
        "1. [Foursquare's 104M Points of Interest](https://tech.marksblogg.com/foursquare-open-global-poi-dataset.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment"
      ],
      "metadata": {
        "id": "b6fuKV-SuRGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_FUV16USK3v"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet duckdb\n",
        "!pip install --quiet jupysql\n",
        "!pip install --quiet duckdb-engine\n",
        "\n",
        "import duckdb\n",
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import urllib\n",
        "import subprocess\n",
        "import json\n",
        "## Setup\n",
        "# Import jupysql Jupyter extension to create SQL cells\n",
        "%load_ext sql\n",
        "\n",
        "%config SqlMagic.autopandas = True\n",
        "%config SqlMagic.feedback = False\n",
        "%config SqlMagic.displaycon = False\n",
        "\n",
        "%sql duckdb:///:memory:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Tippecanoe"
      ],
      "metadata": {
        "id": "j0Uc3pCBuW5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "## Install duckdb CLI quietly\n",
        "curl https://install.duckdb.org | sh > /dev/null 2>&1\n",
        "\n",
        "## Install tippecanoe quietly\n",
        "\n",
        "# Clone the tippecanoe repository from GitHub quietly\n",
        "git clone --quiet https://github.com/mapbox/tippecanoe.git\n",
        "# Enter the tippecanoe folder\n",
        "cd tippecanoe\n",
        "# Build tippecanoe using multiple cores (-j) and silently (-s)\n",
        "make -j -s > /dev/null 2>&1\n",
        "# Install tippecanoe in the system silently\n",
        "make install -s > /dev/null 2>&1\n",
        "# Go back to the previous directory\n",
        "cd ..\n",
        "\n",
        "## Check if duckdb & tippecanoe are installed (minimal output)\n",
        "echo \"Installation complete.\"\n",
        "echo \"Tippecanoe version: $(/content/tippecanoe/tippecanoe --version 2>/dev/null || echo 'Not found')\""
      ],
      "metadata": {
        "id": "q7xqRaIUuYTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Pmtile CLI\n",
        "Refer to this page: [go-pmtiles/releases](https://github.com/protomaps/go-pmtiles/releases)"
      ],
      "metadata": {
        "id": "8-IrSW6Wub-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Download go-pmtiles for Linux x86_64 quietly\n",
        "wget -q https://github.com/protomaps/go-pmtiles/releases/download/v1.28.3/go-pmtiles_1.28.3_Linux_x86_64.tar.gz\n",
        "\n",
        "# Verify SHA256 checksum\n",
        "echo \"06cf492adc2c7fcd23c4f11a98a5292f4cbe04d3afc3a6b38a07bb47452daca2 go-pmtiles_1.28.3_Linux_x86_64.tar.gz\" | sha256sum --check --quiet\n",
        "\n",
        "# Extract quietly\n",
        "tar -xzf go-pmtiles_1.28.3_Linux_x86_64.tar.gz -C /tmp/ > /dev/null 2>&1\n",
        "\n",
        "# Install binary to /usr/local/bin (assuming binary is named 'pmtiles')\n",
        "sudo mv /tmp/pmtiles /usr/local/bin/pmtiles > /dev/null 2>&1\n",
        "\n",
        "# Clean up\n",
        "rm go-pmtiles_1.28.3_Linux_x86_64.tar.gz\n",
        "\n",
        "# Check installation\n",
        "echo \"Installation complete.\"\n",
        "pmtiles version"
      ],
      "metadata": {
        "id": "ks1Y8B2dubr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "Mk6-EkQ2uTPJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ymhQwX4QJEM"
      },
      "source": [
        "## Download OSM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "osm_url = \"https://download.geofabrik.de/asia/india-latest.osm.pbf\"\n",
        "osm_path = \"india-latest.osm.pbf\"\n",
        "\n",
        "if not os.path.exists(osm_path):\n",
        "    print(\"Downloading India OSM extract (~1GB; may take 10-20 mins)...\")\n",
        "    urllib.request.urlretrieve(osm_url, osm_path)\n",
        "    print(\"Download complete.\")"
      ],
      "metadata": {
        "id": "213ZXu08yYor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the PBF file, e.g., 'india-latest.osm.pbf' (regional for practicality)\n",
        "pbf_path = 'india-latest.osm.pbf'  # Replace with your full path\n",
        "folder_path = 'places_by_type'  # Output folder for individual GeoJSON files\n",
        "\n",
        "# Define place_zoom_map as DataFrame for DuckDB registration\n",
        "place_zoom_map = {\n",
        "    'country': {'min_zoom': 0, 'max_zoom': 3},\n",
        "    'state': {'min_zoom': 2, 'max_zoom': 6},\n",
        "    'region': {'min_zoom': 3, 'max_zoom': 7},\n",
        "    'county': {'min_zoom': 4, 'max_zoom': 8},\n",
        "    'district': {'min_zoom': 4, 'max_zoom': 8},\n",
        "    'borough': {'min_zoom': 5, 'max_zoom': 9},\n",
        "    'city': {'min_zoom': 5, 'max_zoom': 10},\n",
        "    'town': {'min_zoom': 7, 'max_zoom': 12},\n",
        "    'suburb': {'min_zoom': 9, 'max_zoom': 13},\n",
        "    'neighbourhood': {'min_zoom': 9, 'max_zoom': 13},\n",
        "    'quarter': {'min_zoom': 10, 'max_zoom': 14},\n",
        "    'village': {'min_zoom': 11, 'max_zoom': 16},\n",
        "    'hamlet': {'min_zoom': 13, 'max_zoom': 17},\n",
        "    'locality': {'min_zoom': 13, 'max_zoom': 17},\n",
        "    'isolated_dwelling': {'min_zoom': 14, 'max_zoom': 18}\n",
        "}\n",
        "zoom_df = pd.DataFrame([\n",
        "    {'place_type': k, 'min_zoom': v['min_zoom'], 'max_zoom': v['max_zoom']} for k, v in place_zoom_map.items()\n",
        "])\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL spatial;\")\n",
        "con.execute(\"LOAD spatial;\")\n",
        "\n",
        "# Register the zoom map DataFrame\n",
        "con.register('zoom_map', zoom_df)\n",
        "\n",
        "# Loop over each place_type and export individual GeoJSON\n",
        "for place_type, zoom_info in place_zoom_map.items():\n",
        "    geojson_file = os.path.join(folder_path, f'{place_type}.geojson')\n",
        "\n",
        "    con.execute(f\"\"\"\n",
        "    COPY (\n",
        "      SELECT\n",
        "        tags['name'] AS place_name,\n",
        "        tags['place'] AS place_type,\n",
        "        TRY_CAST(tags['population'] AS BIGINT) AS population,\n",
        "        ST_Point(CAST(lon AS DOUBLE), CAST(lat AS DOUBLE)) AS geom\n",
        "      FROM ST_ReadOSM('{pbf_path}')\n",
        "      WHERE\n",
        "        tags['name'] IS NOT NULL\n",
        "        AND tags['place'] = '{place_type}'\n",
        "        AND kind = 'node'  -- Ensures point geometries (nodes)\n",
        "        AND lat IS NOT NULL\n",
        "        AND lon IS NOT NULL\n",
        "      -- LIMIT 100  -- Uncomment for testing; remove for full export\n",
        "    ) TO '{geojson_file}' WITH (FORMAT GDAL, DRIVER 'GeoJSON');\n",
        "    \"\"\")\n",
        "\n",
        "    print(f\"Exported {place_type} places to {geojson_file}\")\n",
        "\n",
        "con.close()"
      ],
      "metadata": {
        "id": "xDiAgOz46x98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting to PMTiles Using Tippecanoe"
      ],
      "metadata": {
        "id": "p2fLzXeLOf4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "places_folder = 'places_by_type'  # Input GeoJSON folder\n",
        "pmtiles_folder = 'pmtiles_by_type'  # Temp folder for individual MBTiles\n",
        "merged_mbtiles = 'merged_places.mbtiles'  # Merged output (final MBTiles export)\n",
        "final_pmtiles = 'india_places_combined.pmtiles'  # Final PMTiles\n",
        "\n",
        "# Define place_zoom_map (min_zoom as -Z, max_zoom as -z)\n",
        "place_zoom_map = {\n",
        "    'country': {'min_zoom': 0, 'max_zoom': 3},\n",
        "    'state': {'min_zoom': 2, 'max_zoom': 6},\n",
        "    'region': {'min_zoom': 3, 'max_zoom': 7},\n",
        "    'county': {'min_zoom': 4, 'max_zoom': 8},\n",
        "    'district': {'min_zoom': 4, 'max_zoom': 8},\n",
        "    'borough': {'min_zoom': 5, 'max_zoom': 9},\n",
        "    'city': {'min_zoom': 5, 'max_zoom': 10},\n",
        "    'town': {'min_zoom': 7, 'max_zoom': 12},\n",
        "    'suburb': {'min_zoom': 9, 'max_zoom': 13},\n",
        "    'neighbourhood': {'min_zoom': 9, 'max_zoom': 13},\n",
        "    'quarter': {'min_zoom': 10, 'max_zoom': 14},\n",
        "    'village': {'min_zoom': 11, 'max_zoom': 16},\n",
        "    'hamlet': {'min_zoom': 13, 'max_zoom': 17},\n",
        "    'locality': {'min_zoom': 13, 'max_zoom': 17},\n",
        "    'isolated_dwelling': {'min_zoom': 14, 'max_zoom': 18}\n",
        "}\n",
        "\n",
        "# Create temp folder\n",
        "os.makedirs(pmtiles_folder, exist_ok=True)\n",
        "\n",
        "# List to hold individual MBTiles files\n",
        "mbtiles_files = []\n",
        "\n",
        "# Step 1: Generate individual MBTiles from GeoJSONs\n",
        "for place_type, zoom_info in place_zoom_map.items():\n",
        "    geojson_in = os.path.join(places_folder, f'{place_type}.geojson')\n",
        "    if not os.path.exists(geojson_in):\n",
        "        print(f\"Warning: {geojson_in} not found, skipping {place_type}\")\n",
        "        continue\n",
        "\n",
        "    # Check if GeoJSON is empty\n",
        "    try:\n",
        "        with open(geojson_in, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            if len(data.get('features', [])) == 0:\n",
        "                print(f\"Warning: {geojson_in} is empty, skipping {place_type}\")\n",
        "                continue\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: Invalid JSON in {geojson_in}, skipping {place_type}\")\n",
        "        continue\n",
        "\n",
        "    mb_out = os.path.join(pmtiles_folder, f'{place_type}.mbtiles')\n",
        "    layer_name = place_type\n",
        "\n",
        "    # Tippecanoe to MBTiles with explicit zooms\n",
        "    cmd_tippecanoe = [\n",
        "        'tippecanoe',\n",
        "        '-o', mb_out,\n",
        "        '-l', layer_name,\n",
        "        '-Z', str(zoom_info['min_zoom']),\n",
        "        '-z', str(zoom_info['max_zoom']),\n",
        "        '--force',\n",
        "        '--read-parallel',\n",
        "        '--no-feature-limit',\n",
        "        '--no-tile-size-limit',\n",
        "        geojson_in\n",
        "    ]\n",
        "    result_tip = subprocess.run(cmd_tippecanoe, capture_output=True, text=True)\n",
        "    if result_tip.returncode != 0:\n",
        "        print(f\"Error in tippecanoe for {place_type}: {result_tip.stderr}\")\n",
        "        continue\n",
        "\n",
        "    if not os.path.exists(mb_out) or os.path.getsize(mb_out) == 0:\n",
        "        print(f\"Warning: Empty MBTiles for {place_type}\")\n",
        "        if os.path.exists(mb_out):\n",
        "            os.remove(mb_out)\n",
        "        continue\n",
        "\n",
        "    mbtiles_files.append(mb_out)\n",
        "    print(f\"Created {mb_out} (zoom {zoom_info['min_zoom']}-{zoom_info['max_zoom']})\")\n",
        "\n",
        "# Step 2: Merge MBTiles using tile-join\n",
        "if mbtiles_files:\n",
        "    # Build command: tile-join -f -o merged [sources...]\n",
        "    cmd_join = ['tile-join', '-f', '-o', merged_mbtiles] + mbtiles_files\n",
        "    result_join = subprocess.run(cmd_join, capture_output=True, text=True)\n",
        "    if result_join.returncode != 0:\n",
        "        print(f\"Error in tile-join: {result_join.stderr}\")\n",
        "    else:\n",
        "        print(f\"Merged into {merged_mbtiles}\")\n",
        "\n",
        "        # Step 3: Convert merged MBTiles to PMTiles\n",
        "        cmd_convert = ['pmtiles', 'convert', merged_mbtiles, final_pmtiles]\n",
        "        result_convert = subprocess.run(cmd_convert, capture_output=True, text=True)\n",
        "        if result_convert.returncode != 0:\n",
        "            print(f\"Error in final convert: {result_convert.stderr}\")\n",
        "        else:\n",
        "            print(f\"Final PMTiles: {final_pmtiles}\")\n",
        "            # Show metadata\n",
        "            subprocess.run(['pmtiles', 'show', final_pmtiles])\n",
        "\n",
        "        # Cleanup: Remove individuals but KEEP merged MBTiles and PMTiles\n",
        "        for mb in mbtiles_files:\n",
        "            os.remove(mb)\n",
        "        # Do NOT remove merged_mbtiles or final_pmtiles\n",
        "else:\n",
        "    print(\"No MBTiles to merge.\")"
      ],
      "metadata": {
        "id": "XkK37jny37AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e794249H2Nv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}