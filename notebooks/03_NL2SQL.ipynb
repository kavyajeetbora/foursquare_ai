{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavyajeetbora/foursquare_ai/blob/master/notebooks/03_NL2SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P03ycd4px6D"
      },
      "source": [
        "References for this tutorial:\n",
        "\n",
        "1. [NLP to Sql using Langchain](https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql)\n",
        "2. [NLP to Sql using Langchain - Notebook](https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjx8hB4Sp5c9"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfYYnYhUmiLq",
        "outputId": "9e4e3713-6f79-4d8f-e70b-f3413fb82610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m459.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m814.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-community duckdb langchain-openai duckdb-engine langgraph anytree \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7J6pCAi66s4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from anytree import Node, RenderTree\n",
        "\n",
        "def build_anytree_from_csv(csv_path_or_df):\n",
        "    # Accept file path or DataFrame\n",
        "    if isinstance(csv_path_or_df, str):\n",
        "        df = pd.read_csv(csv_path_or_df)\n",
        "    else:\n",
        "        df = csv_path_or_df\n",
        "\n",
        "    # Specify the order of columns representing the hierarchy\n",
        "    level_cols = [\n",
        "        \"Category_Level_1\",\n",
        "        \"Category_Level_2\",\n",
        "        \"Category_Level_3\",\n",
        "        \"Category_Level_4\",\n",
        "        \"Category_Name\"  # Category_Name is always the leaf\n",
        "    ]\n",
        "\n",
        "    root = Node(\"Root\")\n",
        "    nodes = {\"Root\": root}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        parent = root\n",
        "        path = []\n",
        "        for col in level_cols:\n",
        "            category = row.get(col, None)\n",
        "            if pd.notnull(category) and str(category).strip().lower() != \"nan\":\n",
        "                category = str(category).strip()\n",
        "                path.append(category)\n",
        "                node_key = \"/\".join(path)\n",
        "                if node_key not in nodes:\n",
        "                    nodes[node_key] = Node(category, parent=parent)\n",
        "                parent = nodes[node_key]\n",
        "    return root\n",
        "\n",
        "# Example usage:\n",
        "# tree_root = build_anytree_from_csv('your_categories.csv')\n",
        "# for pre, _, node in RenderTree(tree_root):\n",
        "#     print(f\"{pre}{node.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-YRUWjCr5di"
      },
      "source": [
        "## Setting Up database server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-EeBQbRZPBW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import duckdb\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "from langchain_openai import ChatOpenAI  # Or from langchain_groq import ChatGroq\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langsmith import traceable\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(dotenv_path = '.env', override=True)\n",
        "\n",
        "\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"foursqare_poi_data\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\") # Ensure you have a way to get this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzY0hHbic9wd"
      },
      "outputs": [],
      "source": [
        "def execute_sql(sql_query: str, con):\n",
        "    try:\n",
        "        # Replace {s3_path} if not already in the query\n",
        "        sql_query = sql_query.format(s3_path=S3_PATH)\n",
        "        result = con.execute(sql_query).fetchall()\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error executing SQL: {str(e)}\"\n",
        "\n",
        "def get_duckdb_connection():\n",
        "    con = duckdb.connect(database=':memory:')  # In-memory for simplicity; use a file path for persistence if needed\n",
        "    con.execute(\"INSTALL httpfs;\")\n",
        "    con.execute(\"LOAD httpfs;\")\n",
        "    # Optional: Set S3 region if needed (public bucket, so usually not required)\n",
        "    # con.execute(\"SET s3_region='us-east-1';\")\n",
        "    return con\n",
        "\n",
        "def get_db_schema(S3_PATH, columns):\n",
        "\n",
        "    data_schema = f\"\"\"Columns:\\n\"\"\"\n",
        "\n",
        "    sql_query = f\"SELECT {\",\".join(columns)} FROM read_parquet('{S3_PATH}') WHERE 1=1 AND country='IN'\"\n",
        "\n",
        "    for column in columns:\n",
        "        sql_query += f\" AND {column} IS NOT NULL\"\n",
        "\n",
        "    sql_query += f\" LIMIT 5;\"\n",
        "    sample_result = execute_sql(sql_query, duckdb_conn)\n",
        "\n",
        "    schema_details = execute_sql(f'DESCRIBE {sql_query}', duckdb_conn)\n",
        "\n",
        "    for i, column in enumerate(columns):\n",
        "        data_type = schema_details[i][1]\n",
        "        sample_values = \",\".join([str(r[i]) for r in sample_result])\n",
        "        data_schema += f\"{i+1}. Name: {column} | Data Type: {data_type} | Sample values: {sample_values}\\n\"\n",
        "        data_schema += \"\\n\"\n",
        "    return data_schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJKxv1C7dAdP"
      },
      "source": [
        "## Setup Database Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEvlk_sE2kMz"
      },
      "outputs": [],
      "source": [
        "# Get the DuckDB connection\n",
        "duckdb_conn = get_duckdb_connection()\n",
        "\n",
        "# Create a SQLAlchemy engine from the DuckDB connection\n",
        "# Explicitly specify the duckdb dialect\n",
        "engine = create_engine('duckdb:///:memory:')\n",
        "\n",
        "\n",
        "# Wrap in Langchain's SQLDatabase\n",
        "db = SQLDatabase(engine=engine, sample_rows_in_table_info=2)  # sample_rows_in_table_info helps LLM understand schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Qjdt0VdEIR"
      },
      "source": [
        "## Get the Table Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "51280eb84d464101b55f6ee0c373e078",
            "a57dd96f41d64c2d9a4dbe95c844430b",
            "373b4c653b784c6e9024111363e5fb7d"
          ]
        },
        "id": "JSWXge1z7kSf",
        "outputId": "d452d757-5db4-4481-d227-90b8ba3c1e28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51280eb84d464101b55f6ee0c373e078",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns:\n",
            "1. Name: fsq_place_id | Data Type: VARCHAR | Sample values: 573c6ebc498e8fa95a364a82,54858ef4498e231629a05b63,573c6dc4498e99d57a15fd75,638f03c176296e3553fdfd3d,638f03699ff77807a757a792\n",
            "\n",
            "2. Name: name | Data Type: VARCHAR | Sample values: car nicobar islands,Car Nicobar Airport (CBD),car nicobar islands,Sanenya Beach,Guest House\n",
            "\n",
            "3. Name: latitude | Data Type: DOUBLE | Sample values: 9.152879,9.149272379473922,9.149348,8.458875,8.461575\n",
            "\n",
            "4. Name: longitude | Data Type: DOUBLE | Sample values: 92.822802,92.8182841070909,92.823115,93.0569,93.045784\n",
            "\n",
            "5. Name: postcode | Data Type: VARCHAR | Sample values: 744301,744301,744301,744303,744303\n",
            "\n",
            "6. Name: fsq_category_labels | Data Type: VARCHAR[] | Sample values: ['Landmarks and Outdoors > Island'],['Travel and Transportation > Transport Hub > Airport'],['Landmarks and Outdoors > Island'],['Landmarks and Outdoors > Beach'],['Travel and Transportation > Lodging > Boarding House']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the S3 path (make this configurable)\n",
        "S3_PATH = \"s3://fsq-os-places-us-east-1/release/dt=2025-09-09/places/parquet/places-*.zstd.parquet\"\n",
        "columns = ['fsq_place_id', 'name', 'latitude', 'longitude', 'postcode', 'fsq_category_labels']\n",
        "data_schema = get_db_schema(S3_PATH, columns)\n",
        "\n",
        "print(data_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAqVzvVMdHqz"
      },
      "source": [
        "## Load Environment Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUBHJOUNDgNs"
      },
      "source": [
        "Explore the chatgpt model pricing here:\n",
        "https://platform.openai.com/docs/pricing\n",
        "\n",
        "- ✅ Cheapest overall → gpt-5-nano ($0.45 per 2M tokens processed)\n",
        "\n",
        "- ⚖️ Second cheapest → gpt-4.1-nano ($0.50)\n",
        "\n",
        "- Use openai tokenizer to count the number of tokens for given input: https://platform.openai.com/tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imwGJwLDCZYO"
      },
      "outputs": [],
      "source": [
        "# Initialize LLM (replace with your API key)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)  # Or ChatGroq(model=\"grok-beta\", api_key=\"YOUR_XAI_API_KEY\")\n",
        "\n",
        "# Pre-prompt for NL-to-SQL (customize this!)\n",
        "# Updated prompt to include required input variables for create_sql_query_chain\n",
        "# and incorporate the S3_PATH as a partial variable\n",
        "SQL_PROMPT_TEMPLATE = \"\"\"\n",
        "You are a SQL expert for querying Foursquare POI data using DuckDB. The data is in Parquet files at {s3_path}.\n",
        "The schema includes columns: name (string), country (string, e.g., 'IN' for India), location (struct with lat/lng), categories (array), etc.\n",
        "\n",
        "Based on the schema below and the user's question, generate a valid DuckDB SQL query.\n",
        "Schema:\n",
        "{table_info}\n",
        "\n",
        "Contraints:\n",
        "Always restrict the oulets aka POI withing INDIA so always use country = 'IN' in WHERE clause in all generated SQL queries.\n",
        "If any country is asked by the uers just say something like beyond scope and donot generate any sql prompt\"\n",
        "\n",
        "User question: {input}\n",
        "Limit the results to {top_k}.\n",
        "\n",
        "Generate a valid DuckDB SQL query to answer this. Always use read_parquet('{s3_path}') as the data source.\n",
        "Do not add explanations; output only the SQL query.\n",
        "Examples:\n",
        "- Question: How many Starbucks Outlets are there in India?\n",
        "  SQL: SELECT COUNT(*) as count FROM read_parquet('{s3_path}') WHERE LOWER(name) LIKE '%starbucks%' OR '%starbucks%' IN (SELECT LOWER(unnest(fsq_category_labels))))\n",
        "AND country = 'IN';\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template with the required input variables and partial variable for S3_PATH\n",
        "sql_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"top_k\", \"table_info\"],\n",
        "    template=SQL_PROMPT_TEMPLATE,\n",
        "    partial_variables={\"s3_path\": S3_PATH}\n",
        ")\n",
        "\n",
        "# Now create the chain using the updated prompt\n",
        "sql_chain = create_sql_query_chain(llm=llm, db=db, prompt=sql_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSW_-W7hrTfz"
      },
      "source": [
        "Track the LLM traces in this dashboard: https://smith.langchain.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtxKZItHXOcB",
        "outputId": "b064cd8a-1900-4deb-cece-c3edfb039500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```sql\n",
            "SELECT COUNT(*) as count FROM read_parquet('s3://fsq-os-places-us-east-1/release/dt=2025-09-09/places/parquet/places-*.zstd.parquet') WHERE LOWER(name) LIKE '%biryani%' OR '%biryani%' IN (SELECT LOWER(unnest(categories))) AND country = 'IN';\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "question = \"How many number of biryani outlets are there in India ?\"\n",
        "sql_input = {\"input\": question, \"question\": question, \"s3_path\": S3_PATH, \"top_k\": 1, \"table_info\": data_schema} # Include both 'input' and 'question' keys\n",
        "sql_query = sql_chain.invoke(sql_input).strip()  # Strip any extra whitespace\n",
        "print(sql_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a43Q6hNnVvOc"
      },
      "outputs": [],
      "source": [
        "RESPONSE_PROMPT_TEMPLATE = \"\"\"\n",
        "Query results: {results}\n",
        "\n",
        "Based on the results, provide a friendly, easy-to-understand answer to the user's question: {question}\n",
        "Keep it concise and natural.\n",
        "\"\"\"\n",
        "\n",
        "response_prompt = PromptTemplate.from_template(RESPONSE_PROMPT_TEMPLATE)\n",
        "response_chain = response_prompt | llm  # Simple chain: prompt -> LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4nRoT3CSV2o",
        "outputId": "7e908fe5-2e91-4b22-ff22-1f8048eda0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT COUNT(*) as count FROM read_parquet('s3://fsq-os-places-us-east-1/release/dt=2025-09-09/places/parquet/places-*.zstd.parquet') WHERE 'retail' IN (SELECT LOWER(unnest(categories))) AND country = 'IN';\n",
            "It looks like there was an error in the SQL query used to find the count of retail stores in India. Specifically, the column \"categories\" isn't recognized in the data source being queried. To get the count of retail stores, you might want to check the column names and ensure \"categories\" is included in the correct part of the query. If you make those adjustments, we should be able to find the information you need!\n"
          ]
        }
      ],
      "source": [
        "question = \"What is the count of retail stores in India?\"\n",
        "sql_input = {\"input\": question, \"question\": question, \"s3_path\": S3_PATH, \"top_k\": 10} # Include both 'input' and 'question' keys\n",
        "\n",
        "# Wrap the chain invocation with @traceable\n",
        "@traceable\n",
        "def get_sql_query(sql_input):\n",
        "    return sql_chain.invoke(sql_input).strip()  # Strip any extra whitespace\n",
        "\n",
        "sql_query = get_sql_query(sql_input)\n",
        "\n",
        "# Remove markdown code block formatting if present\n",
        "if sql_query.startswith(\"```sql\") and sql_query.endswith(\"```\"):\n",
        "    sql_query = sql_query[6:-3].strip() # Remove \"```sql\" and \"```\" and strip whitespace\n",
        "\n",
        "print(sql_query)\n",
        "\n",
        "result = execute_sql(sql_query, duckdb_conn)\n",
        "\n",
        "# Step 3: Generate friendly response\n",
        "response_input = {\"results\": json.dumps(result), \"question\": question}  # Convert results to string/JSON\n",
        "\n",
        "@traceable\n",
        "def generate_friendly_response(response_input):\n",
        "    return response_chain.invoke(response_input).content\n",
        "\n",
        "friendly_response = generate_friendly_response(response_input)\n",
        "\n",
        "print(friendly_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AV4B4dJxDuvG",
        "outputId": "d3be7564-b368-43df-c8ad-b72b59765fe0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Error executing SQL: \"\\'a\\'\"'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"SELECT unnest({'a': [1, 2, 3], 'b': 88}, recursive := true);\"\n",
        "execute_sql(query, duckdb_conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqBGmfusronz"
      },
      "source": [
        "## Business Use Cases\n",
        "\n",
        "1. How many Pizza Hut locations are there in India?\n",
        "2. What is the count of convenience stores in India?\n",
        "3. List the top 10 cities in India with the most fast food restaurants.\n",
        "4. How many grocery stores are there in New Delhi?\n",
        "5. Find beverage stores near latitude 19.0760, longitude 72.8777 (Mumbai).\n",
        "6. What is the number of cafes in India that were created after 2024-01-01?\n",
        "7. Count of McDonald's locations in India.\n",
        "8. Top 5 states in India with the highest number of restaurants.\n",
        "9. How many supermarkets have been closed in India this year?\n",
        "10. List fast food places in Bengaluru with a website.\n",
        "11. What is the average latitude of convenience stores in India?\n",
        "12. Count of POIs categorized as 'Food and Beverage Shop' in India.\n",
        "13. Find Pizza Hut outlets in Mumbai, India.\n",
        "14. How many beverage-related POIs are there in India?\n",
        "15. Top cities in India with the most health food stores (potential competitors to sugary beverages).\n",
        "16. Count of restaurants with Instagram handles in India.\n",
        "17. List closed fast food locations in India since 2023.\n",
        "18. How many grocery stores are in postal code 400001 (Mumbai)?\n",
        "19. Find nearby cafes to latitude 28.7041, longitude 77.1025 (Delhi) within a small radius.\n",
        "20. What is the total number of retail food stores in India that have a telephone number?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnq6puv/kzX2m63XLkMJOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "373b4c653b784c6e9024111363e5fb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "black",
            "description_width": ""
          }
        },
        "51280eb84d464101b55f6ee0c373e078": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a57dd96f41d64c2d9a4dbe95c844430b",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_373b4c653b784c6e9024111363e5fb7d",
            "value": 100
          }
        },
        "a57dd96f41d64c2d9a4dbe95c844430b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}